{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "220601_PracticalWeek02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNChukxvoat/KXiFWiVDX1u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/angelcolab97/principles_of_ai/blob/main/220601_PracticalWeek02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHX_M0hhpASq"
      },
      "source": [
        "# Principles of AI\n",
        "# TutorialWeek02 — NLP (Sentiment Analysis)\n",
        "\n",
        "\n",
        "Sentiment Analysis will be the focus of this section (previously presented in Section 2.6)\n",
        "Sentiment analysis (or opinion mining) is a natural language processing (NLP) technique used to determine whether data is positive, negative, or neutral. Text document can be used for sentiment analysis, which helps businesses monitor customer feedback and better understand their customers' needs. \n",
        " \n",
        "For this exercise, we'll look at three datasets that contain sentences with positive or negative sentiment labels. These data sets were compiled from product, movie, and restaurant reviews found on three different websites:\n",
        "\n",
        ">- amazon.com\n",
        ">- imdb.com\n",
        ">- yelp.com\n",
        "\n",
        "**Outline**\n",
        "1. Introduction to the dataset\n",
        "2. Importing Libraries and File Integration\n",
        "3. Split data into Train Features & Train Labels\n",
        "4. Training and Testing the Model\n",
        "\n",
        "**Source**  \n",
        "This exercise is based on the Paper 'From Group to Individual Labels using Deep Features', Kotzias et. al,. KDD 2015 \n",
        "[[source](https://dl.acm.org/doi/10.1145/2783258.2783380)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "jupyter nbconvert --to html /content/220601_PracticalWeek02.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xvytMhFdb97",
        "outputId": "705ed652-9818-4338-8ba0-faac1cb5a0df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook /content/220601_PracticalWeek02.ipynb to html\n",
            "[NbConvertApp] Writing 304171 bytes to /content/220601_PracticalWeek02.html\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "CWjgWpSrTgPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg2rMNNUboD9"
      },
      "source": [
        "### 1. Introduction to the dataset\n",
        "\n",
        "Let's begin by importing two (2) essential libraries:\n",
        "* **pandas**: Pandas is a popular open source   Python package for data science/data analysis and machine learning tasks. It   provides high-performance, user-friendly data structures and data analysis   tools for Python programming.   \n",
        "The import pandas statement   instructs Python to import the pandas data analysis library into your current   environment. The as pd section of the code then instructs Python to assign   pandas the alias pd. You can use pandas functions by simply typing pd.\n",
        "* **numpy**: NumPy (short for Numerical Python)   is a fast interface for storing and manipulating dense data buffers. NumPy   arrays are similar to Python's built-in list type in some ways, but NumPy   arrays provide much more efficient storage and data operations as the arrays   grow in size.  \n",
        "NumPy arrays are at the heart of nearly the entire ecosystem of   Python data science tools, and we can use them to create and manipulate   vectors and matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iG8_h7yK9LrS"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsgfchU5bsWJ"
      },
      "source": [
        "Next import the files and then uploading them to Google Colab. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "PnmpvJX-9Nto",
        "outputId": "f67da47f-6844-4ef5-a88c-e9e2e9543381"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4f759083-ac75-434a-ac6e-75ff7e0d1b58\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4f759083-ac75-434a-ac6e-75ff7e0d1b58\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving yelp_labelled.txt to yelp_labelled.txt\n",
            "Saving imdb_labelled.txt to imdb_labelled.txt\n",
            "Saving amazon_cells_labelled.txt to amazon_cells_labelled.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Then, we are going to read each line from both files and add it to the same list (“lines”). \n",
        "* To read a file in Python, we must open the file in reading “r” mode\n"
      ],
      "metadata": {
        "id": "mxuofoSSMiE3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z_TVAZM9ax8"
      },
      "source": [
        "with open(\"imdb_labelled.txt\", \"r\") as text_file:\n",
        "    lines = text_file.read().split(\"\\n\")\n",
        "with open(\"amazon_cells_labelled.txt\", \"r\") as text_file:\n",
        "    lines = text_file.read().split(\"\\n\")\n",
        "with open(\"yelp_labelled.txt\", \"r\") as text_file:\n",
        "    lines = text_file.read().split(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we are going to split by tab and get rid of any corrupted data or lines that aren't separated by tabs.\n",
        "\n",
        "* Tabs are represented in .txt files as the escape character \"\\t\". \n",
        "* In the first line, splitting a string by tabs splits the string at each tab and returns a list containing the resulting substrings.\n",
        "* The second to fourth line of command is a for loop used to extract only sentences that are separated by tabs. \n"
      ],
      "metadata": {
        "id": "_ngJLWrDMwxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "newLines = [line.split(\"\\t\")\n",
        "            for line in lines \n",
        "            if len(line.split(\"\\t\")) == 2 and\n",
        "            line.split(\"\\t\")[1] != \"\"]"
      ],
      "metadata": {
        "id": "IvaxWFn09bd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Let’s check the difference between these two list: **lines** vs. **newLines**. \n",
        "* The command below will print the first ten sentences in the list lines and newLines"
      ],
      "metadata": {
        "id": "b7C-S7WdM7wx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lines[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BPIwHu_-nP1",
        "outputId": "2d3d3dbe-446c-424d-9f5f-c2bbf5830c80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Wow... Loved this place.\\t1',\n",
              " 'Crust is not good.\\t0',\n",
              " 'Not tasty and the texture was just nasty.\\t0',\n",
              " 'Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.\\t1',\n",
              " 'The selection on the menu was great and so were the prices.\\t1',\n",
              " 'Now I am getting angry and I want my damn pho.\\t0',\n",
              " \"Honeslty it didn't taste THAT fresh.)\\t0\",\n",
              " 'The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.\\t0',\n",
              " 'The fries were great too.\\t1',\n",
              " 'A great touch.\\t1']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newLines[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8Gts8yg-kTS",
        "outputId": "97eb4ccd-98a3-445a-8fcc-132cc7048169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Wow... Loved this place.', '1'],\n",
              " ['Crust is not good.', '0'],\n",
              " ['Not tasty and the texture was just nasty.', '0'],\n",
              " ['Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.',\n",
              "  '1'],\n",
              " ['The selection on the menu was great and so were the prices.', '1'],\n",
              " ['Now I am getting angry and I want my damn pho.', '0'],\n",
              " [\"Honeslty it didn't taste THAT fresh.)\", '0'],\n",
              " ['The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.',\n",
              "  '0'],\n",
              " ['The fries were great too.', '1'],\n",
              " ['A great touch.', '1']]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also examine the sentiment distribution of the datasets to ensure that we do not have an imbalanced dataset.\n",
        "\n",
        "A dataset that is imbalanced has large differences in the distribution of its classes. This means that a dataset is biassed towards one of its classes. If a dataset is biassed towards one class, an algorithm trained on the same data will also be biassed towards that class.\n",
        "\n",
        "Output below depicts 500 sentences labelled as “1”,  and 500 sentences labelled as “0”. That is, our dataset is not biassed towards any classes, negative or positive sentences."
      ],
      "metadata": {
        "id": "vE7Uhx9SNHU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Check Sentiment Distribution of the Current Dataset\n",
        "from collections import Counter\n",
        "sentiment_distr = Counter([label for (words, label) in newLines])\n",
        "print(sentiment_distr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7YqcHRaZkuj",
        "outputId": "deaeb61a-622c-4779-de22-dac4504e3314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'1': 500, '0': 500})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjXsndrxbzyr"
      },
      "source": [
        "### 3. Split data into Train Features & Train Labels:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature sets and labels are frequently separated as two units in most machine learning (ML) steps, we split our training data into 'train document'  and  'train label' as the features (X) and labels (y) in training. The newLines list will then be divided into train documents and train labels."
      ],
      "metadata": {
        "id": "jK0oCLSvNOYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate the sentences\n",
        "train_documents = [line[0] for line in newLines ]\n",
        "# train_documents\n",
        "train_documents[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAZpAU3m_mNR",
        "outputId": "b6c3dfae-9afe-43e0-9f1b-6e007ca842c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Wow... Loved this place.',\n",
              " 'Crust is not good.',\n",
              " 'Not tasty and the texture was just nasty.',\n",
              " 'Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.',\n",
              " 'The selection on the menu was great and so were the prices.',\n",
              " 'Now I am getting angry and I want my damn pho.',\n",
              " \"Honeslty it didn't taste THAT fresh.)\",\n",
              " 'The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.',\n",
              " 'The fries were great too.',\n",
              " 'A great touch.']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate the labels\n",
        "train_labels = [int(line[1]) for line in newLines]\n",
        "train_labels[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYiP_395_5CJ",
        "outputId": "3f7ea0b4-1e75-4289-b70d-1362b934d1b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 0, 0, 1, 1, 0, 0, 1, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use Scikit-learn's CountVectorizer to convert a set of text documents into a vector of term/token counts. CountVectorizer allows for the pre-processing of text data before generating the vector representation.\n",
        "\n",
        "* Scikit-learn\tScikit-learn is a free Python machine learning library. It supports Python numerical and scientific libraries such as NumPy and SciPy, as well as various algorithms such as support vector machine, random forests, and k-neighbors.\n",
        "* CountVectorizer\tCountVectorizer generates a matrix in which each unique word is represented by a column and each text sample from the document is represented by a row. The value of each cell is simply the number of words in that text sample. This is useful when we have multiple such texts and want to convert each word into a vector (for using in further text analysis).\n"
      ],
      "metadata": {
        "id": "Peow3NTQNW6Y"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHGZDc7C9hg4"
      },
      "source": [
        "# Import CountVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, instantiate an object from CountVectorizer and convert convert the train_documents into a matrix of token counts.\n",
        "\n",
        "* To ‘instantiate’ —\tIn an object-oriented programming (OOP) language, instantiating means creating an instance of an object. A named instantiated object is created in memory or on disc using the structure described in a class declaration. \n",
        "* fit_transform() —\tThis fit_transform() method is essentially a combination of the fit and transform methods. \n",
        "It is equivalent to fit(). transform(). This method fits and transforms the input data at the same time and converts the data points.\n",
        "*fit() —\tThis function takes the training data as arguments\n",
        "transform()\tThis function allows you to execute a function for each value of the DataFrame.\n",
        "\n",
        "When we called fit_transform here, it means you want to convert the train_documents into a matrix of token counts using the function CountVectorizer \n"
      ],
      "metadata": {
        "id": "Vg8CK4kUNial"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zstq21tS9l65"
      },
      "source": [
        "# Instatiate the Countvectorizer\n",
        "count_vectorizer = CountVectorizer(binary=\"true\")\n",
        "\n",
        "# Convert the training set to a matrix of token counts:\n",
        "train_documents = count_vectorizer.fit_transform(train_documents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIiTmy5ocoJh"
      },
      "source": [
        "### 4. Training and Testing The Model \n",
        "\n",
        "The Naive Bayes algorithm will be used to train our documents. The Naive Bayes classification algorithm is used to solve binary (two-class) and multiclass classification problems. Because the calculations of the probabilities for each class are simplified to make their calculations tractable, it is known as Naive Bayes or idiot Bayes (we will explore this further in Week 4)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Navie Bayes Algorithm:\n",
        "from sklearn.naive_bayes import BernoulliNB"
      ],
      "metadata": {
        "id": "lAK_Sy15CbTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJu77m6S9o4E"
      },
      "source": [
        "# Fit the BernoulliNB Classifier:\n",
        "classifier = BernoulliNB().fit(train_documents, train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJWyBPPGctvP"
      },
      "source": [
        "The Python predict() function will be used to predicts the labels of the sentence values based on the trained model. The predict() function only accepts one argument, which is typically the data to be tested. \n",
        "\n",
        "Output below depicts a prediction that resulted in a positive sentiment, as indicated by the index “1”.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cU6XzKYFMSV",
        "outputId": "ac070bce-9c5c-4c1d-815f-7f74e8c06f4e"
      },
      "source": [
        "#Example 1\n",
        "classifier.predict(count_vectorizer.transform([\"The best movie ever\"]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On the other hand, output below depicts a prediction that resulted in a negative sentiment, as indicated by the index “2”."
      ],
      "metadata": {
        "id": "tnvdiE7WOBh_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWREYK3HFWhc",
        "outputId": "1b415a57-0de2-4fd1-aeb4-cbea7a4bf5aa"
      },
      "source": [
        "#Example 2\n",
        "classifier.predict(count_vectorizer.transform(['worst movie ever']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It would be more efficient to interpret the sentiment by writing a function that:\n",
        ">- converts “0” to negative sentiment → line 4 and 5\n",
        ">- converts “1” to positive sentiment → line 6 and 7\n"
      ],
      "metadata": {
        "id": "1sflyQpzOJXw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKqjE9l39ss9"
      },
      "source": [
        "# Create a function to output the Sentiment Analysis Label of a sentence:\n",
        "def predictionOutput(sentence):\n",
        "    prediction = classifier.predict(count_vectorizer.transform([sentence]))\n",
        "    if(prediction[0] == 1):\n",
        "        print(\"This is a Positive Sentiment Sentence\")\n",
        "    elif (prediction[0] == 0):\n",
        "        print(\"This is a Negative Sentiment Sentence\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now invoke the function predictionOutput()' that we created earlier and pass some sentences for prediction.\n",
        "\n",
        "The predicted output is shown in the output below. In this case, we can say that the model reasonably predicts the sentiment of the sentences. However, this is merely an example of how sentiment analysis works. We will need to tweak our predictive modelling approach to avoid overfitting.\n",
        "\n",
        "Overfitting occurs when a model learns too much detail and noise in the training data, resulting in poor performance on new data. This means that the model detects noise or random fluctuations in the training data and recognises them as concepts.\n",
        "\n",
        "The content for weeks 3 and 4 will go over these issues and the concept of overfitting in greater depth."
      ],
      "metadata": {
        "id": "rvT9gDMCOSSh"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sShFFiUt90K0",
        "outputId": "6323e857-c67d-4330-c181-e7d1a034bab9"
      },
      "source": [
        "# Testing our model with custom sentences/data:\n",
        "predictionOutput(\"I am having a very good and great day\")\n",
        "predictionOutput(\"What a brilliant movie\")\n",
        "predictionOutput(\"He thinks that movie was a bit long\")\n",
        "predictionOutput(\"My sister said it was waste of money and time\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a Positive Sentiment Sentence\n",
            "This is a Positive Sentiment Sentence\n",
            "This is a Negative Sentiment Sentence\n",
            "This is a Negative Sentiment Sentence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##End of TutorialWeek02"
      ],
      "metadata": {
        "id": "n5f3uNYgObmD"
      }
    }
  ]
}